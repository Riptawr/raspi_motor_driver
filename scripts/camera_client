#!/usr/bin/env python

import rospy
from sensor_msgs.msg import Image, CompressedImage

import cv2  # OpenCV for perspective transform
import numpy as np

# We do not use it, since CompressedImage is not supported
from cv_bridge import CvBridge, CvBridgeError
VERBOSE = False


class CamProcessing(object):
    def __init__(self):
        rospy.init_node('cam_processing', anonymous=True)

        self.source = np.float32([[14, 140], [301, 140], [200, 96], [118, 96]])
        self.dst_size = 5
        self.bottom_offset = 10
        self.pub = rospy.Publisher('/raspi_motor_driver/image', Image, queue_size=24)
        self.bridge = CvBridge()

    def subscribe(self):
        # rospy.Subscriber('/usb_cam/image_raw', Image, self.callback)
        rospy.Subscriber('/raspicam_node/image', Image, self.callback, queue_size=1)
        rospy.spin()

    @staticmethod
    def emergency_stop(image):
        if all(value == image.data[0] for value in image.data):
            """ Uniform image ahead -> Stop"""
            rospy.logwarn("stopping!!!")
        else:
            rospy.loginfo("all is well")

    def callback(self, ros_data):
        """Callback function of subscribed topic.
        Here images get converted and features detected"""
        if VERBOSE:
            rospy.logdebug('received image of type: "%s"' % ros_data)

        #### direct conversion to CV2 ####
        # np_arr = np.fromstring(ros_data.data, np.uint8)
        # image_np = cv2.imdecode(np_arr, cv2.CV_LOAD_IMAGE_COLOR)
        image_np = self.bridge.imgmsg_to_cv2(ros_data, "bgr8")

        gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)
        sift = cv2.xfeatures2d.SURF_create()
        detector = sift.detect(gray, None)

        kpts, des = sift.compute(gray, detector)
        # kpts,des=descriptor.compute(gray,kpts)
        im_with_keypoints = cv2.drawKeypoints(gray, kpts, np.array([]), color=255,
                                              flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

        msg = self.bridge.cv2_to_imgmsg(im_with_keypoints, "bgr8")
        # Publish new image
        self.pub.publish(msg)

    def perspect_transform(self, image):
        src = self.source
        bottom_offset = self.bottom_offset
        dst_size = self.dst_size
        dst = np.float32([[image.shape[1] / 2 - dst_size, image.shape[0] - bottom_offset],
                          [image.shape[1] / 2 + dst_size, image.shape[0] - bottom_offset],
                          [image.shape[1] / 2 + dst_size, image.shape[0] - 2 * dst_size - bottom_offset],
                          [image.shape[1] / 2 - dst_size, image.shape[0] - 2 * dst_size - bottom_offset],
                          ])

        img = image  # ROS raw_image specifics
        M = cv2.getPerspectiveTransform(src, dst)
        warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))  # keep same size as input image

        return warped


if __name__ == '__main__':
    try:
        node = CamProcessing()
        start_time = 0

        while not start_time:
            start_time = rospy.Time.now().to_sec()

        while not rospy.is_shutdown():
            elapsed = rospy.Time.now().to_sec() - start_time
            node.subscribe()


    except rospy.ROSInterruptException:
        # GPIO.cleanup()
        pass